import sys
import os
# Ajouter le r√©pertoire parent au path pour pouvoir importer utils
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import requests
import urllib3
import time
import json
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Optional
import pandas as pd
import pytz
from utils.flight_html_parser import ParserHtml
from utils.ftp_manager import FTPManager
from config.simple_logger import get_logger

# D√©sactiver les warnings SSL pour ce scraper sp√©cifique
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


class FlightDataScraper:
    """
    Scraper pour r√©cup√©rer les donn√©es de vols depuis airportinfo.live
    """

    def __init__(self, lang: str = "en", use_cache_server: bool = False, cache_server_url: str = None):
        """
        Initialise le scraper avec la langue sp√©cifi√©e
        
        Args:
            lang: Langue pour les requ√™tes (d√©faut: "en")
            use_cache_server: Si True, utilise le serveur cache au lieu d'airportinfo.live
            cache_server_url: URL du serveur cache (optionnel)
        """
        self.logger = get_logger(__name__)
        self.use_cache_server = use_cache_server
        
        if use_cache_server:
            self.base_url = cache_server_url
            self.logger.info(f"Initialisation du scraper avec serveur cache: {self.base_url}")
        else:
            self.base_url = "https://data.airportinfo.live/airportic.php"
            self.logger.info(f"Initialisation du scraper (langue: {lang})")
        
        self.lang = lang
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Content-Type": "application/x-www-form-urlencoded"
        }
        self.parser = ParserHtml()

    def _handle_rate_limit(self, attempt: int, max_retries: int) -> bool:
        """
        G√®re le rate limiting avec backoff exponentiel
        
        Args:
            attempt: Num√©ro de la tentative actuelle (0-index√©)
            max_retries: Nombre maximum de tentatives
            
        Returns:
            True si on doit continuer √† essayer, False sinon
        """
        if attempt >= max_retries - 1:
            return False
            
        wait_time = (2 ** attempt) * 5  # Backoff exponentiel: 5s, 10s, 20s
        self.logger.warning(f"Rate limit atteint. Attente de {wait_time}s (tentative {attempt + 1}/{max_retries})")
        time.sleep(wait_time)
        return True

    def fetch(self, iata_airport: str, date: str, dep_arr: str = "arrival", 
              shift: str = "00", max_retries: int = 3, ftp_config: Optional[Dict] = None) -> List[Dict]:
        """
        R√©cup√®re les donn√©es de vol pour un a√©roport, une date et une heure donn√©s
        
        Args:
            iata_airport: Code IATA de l'a√©roport
            date: Date au format YYYY-MM-DD
            dep_arr: Type de vol ("arrival" ou "departure")
            shift: Heure au format HH (00-23)
            max_retries: Nombre maximum de tentatives
            ftp_config: Configuration FTP pour envoyer la r√©ponse brute
            
        Returns:
            Liste des vols trouv√©s, liste vide en cas d'erreur
        """
        self.logger.info(f"Requ√™te {dep_arr} pour {iata_airport} - shift {shift}...")
        
        payload = {
            "lang": self.lang,
            "iataAirport": iata_airport,
            "depArr": dep_arr,
            "date": date,
            "shift": str(shift),
            "exec": "1",
            "type": "refresh"
        }

        for attempt in range(max_retries):
            try:
                response = requests.post(self.base_url, headers=self.headers, data=payload, timeout=30, verify=False)
                
                if response.status_code == 429:  # Too Many Requests
                    if not self._handle_rate_limit(attempt, max_retries):
                        break
                    continue
                
                response.raise_for_status()
                self.logger.info(f"‚úì Succ√®s requ√™te {iata_airport} shift {shift} ({dep_arr})")
                
                # Upload de la r√©ponse brute vers FTP si configur√©
                if ftp_config:
                    self._upload_raw_response_to_ftp(response, iata_airport, date, shift, dep_arr, ftp_config)
                
                flights = self.parser.parse_flights_html(
                    response.text, 
                    date=date, 
                    iata_airport=iata_airport, 
                    dep_arr=dep_arr
                )
                
                return flights if isinstance(flights, list) else []
                
            except requests.exceptions.HTTPError as e:
                if response.status_code == 429:
                    if not self._handle_rate_limit(attempt, max_retries):
                        break
                    continue
                else:
                    self.logger.error(f"HTTP {response.status_code} pour {iata_airport} shift {shift}: {e}")
                    
            except requests.exceptions.RequestException as e:
                self.logger.error(f"Requ√™te pour {iata_airport} shift {shift}: {e}")
                
            except Exception as e:
                self.logger.error(f"Inattendue pour {iata_airport} shift {shift}: {e}")
            
            # Attendre avant de r√©essayer (sauf pour la derni√®re tentative)
            if attempt < max_retries - 1:
                time.sleep(2)
        
        self.logger.error(f"√âchec apr√®s {max_retries} tentatives pour {iata_airport} shift {shift}")
        return []

    def save_to_json(self, data: List[Dict], filename: str, output_folder: str = "output") -> bool:
        """
        Sauvegarde les donn√©es dans un fichier JSON dans le dossier sp√©cifi√©
        
        Args:
            data: Donn√©es √† sauvegarder
            filename: Nom du fichier
            output_folder: Dossier de destination
            
        Returns:
            True si la sauvegarde a r√©ussi, False sinon
        """
        try:
            # Cr√©er le chemin vers le dossier de sortie
            output_dir = os.path.join(
                os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 
                output_folder
            )
            
            # Cr√©er le dossier s'il n'existe pas
            os.makedirs(output_dir, exist_ok=True)
            
            # Chemin complet du fichier
            filepath = os.path.join(output_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"‚úì Donn√©es sauvegard√©es dans {filepath}")
            return True
            
        except Exception as e:
            self.logger.error(f"Impossible de sauvegarder dans {filename} : {e}")
            return False

    def _upload_raw_response_to_ftp(self, response, iata_airport: str, date: str, 
                                    shift: str, dep_arr: str, ftp_config: Dict) -> None:
        """Upload la r√©ponse HTTP brute vers un serveur FTP et nettoie les vieux fichiers"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"raw_{iata_airport}_{dep_arr}_{date}_{shift}h_{timestamp}.html"
            
            self.logger.info(f"Upload FTP de la r√©ponse brute: {filename}")
            
            with FTPManager(
                host=ftp_config.get('host'),
                port=ftp_config.get('port', 21),
                username=ftp_config.get('username', ''),
                password=ftp_config.get('password', ''),
                use_tls=ftp_config.get('use_tls', False),
                remote_directory=ftp_config.get('remote_directory', '/')
            ) as ftp:
                if ftp.ftp:
                    from io import BytesIO
                    content_bytes = response.content
                    file_obj = BytesIO(content_bytes)
                    
                    # Upload du nouveau fichier
                    ftp.ftp.storbinary(f'STOR {filename}', file_obj)
                    self.logger.info(f"‚úì Upload FTP r√©ussi: {filename} ({len(content_bytes)} octets)")
                    
                    # Nettoyage des vieux fichiers (max 24h)
                    max_age_hours = ftp_config.get('cleanup_max_age_hours', 24)
                    if max_age_hours > 0:
                        deleted = ftp.cleanup_old_files(pattern="raw_*.html", max_age_hours=max_age_hours)
                        if deleted > 0:
                            self.logger.info(f"üóëÔ∏è  Nettoyage FTP: {deleted} fichier(s) supprim√©(s)")
                else:
                    self.logger.error("‚úó Impossible de se connecter au serveur FTP")
                    
        except Exception as e:
            self.logger.error(f"Erreur lors de l'upload FTP de la r√©ponse brute: {e}")


    def fetch_next_hour_departures_top_airports(self, num_airports: int = 200, 
                                               delay: float = 2.0, 
                                               hour_offset: int = 1,
                                               ftp_config: Optional[Dict] = None) -> List[Dict]:
        """
        R√©cup√®re les d√©parts pour une heure sp√©cifique pour les N premiers a√©roports
        en tenant compte du timezone de chaque a√©roport
        
        Args:
            num_airports: Nombre d'a√©roports √† traiter (d√©faut: 200)
            delay: D√©lai entre les requ√™tes pour √©viter le rate limiting
            hour_offset: D√©calage en heures par rapport √† l'heure actuelle
                        Exemples: 1 = prochaine heure, 0 = heure actuelle, -1 = heure pr√©c√©dente
            ftp_config: Configuration FTP pour l'upload automatique des r√©ponses brutes
                       Format: {
                           'host': 'ftp.example.com',
                           'port': 21,
                           'username': 'user',
                           'password': 'pass',
                           'use_tls': False,
                           'remote_directory': '/uploads'
                       }
        
        Returns:
            Liste de tous les vols de d√©part pour l'heure cibl√©e
        """
        offset_desc = self._get_offset_description(hour_offset)
        self.logger.info(f"R√©cup√©ration des d√©parts pour {offset_desc} pour les {num_airports} premiers a√©roports")
        
        # Charger les donn√©es des a√©roports
        airports_df = self._load_airports_data()
        if airports_df is None:
            return []
        
        # Prendre les N premiers a√©roports
        top_airports = airports_df.head(num_airports)
        self.logger.info(f"{len(top_airports)} a√©roports charg√©s depuis le fichier CSV")
        
        all_flights = []
        utc_now = datetime.now(timezone.utc)
        
        for index, airport in top_airports.iterrows():
            iata_code = airport['code_iata']
            timezone_name = airport['timezone']
            
            # Log de progression
            self.logger.info(f"[{index + 1}/{num_airports}] Traitement de l'a√©roport {iata_code}...")
            
            try:
                flights = self._fetch_airport_flights(
                    iata_code, timezone_name, utc_now, hour_offset, index, num_airports, ftp_config
                )
                
                if flights:
                    all_flights.extend(flights)
                    self.logger.info(f"‚úì {iata_code}: {len(flights)} vols de d√©part trouv√©s")
                else:
                    self.logger.info(f"‚ö† {iata_code}: Aucun vol de d√©part trouv√©")
                    
            except Exception as e:
                self.logger.error(f"‚úó {iata_code}: {e}")
            
            # D√©lai entre les requ√™tes (seulement si on utilise airportinfo.live)
            if index < len(top_airports) - 1 and not self.use_cache_server:
                time.sleep(delay)
        
        self.logger.info(f"Total de {len(all_flights)} vols de d√©part r√©cup√©r√©s pour l'heure cible")
        
        return all_flights

    def _get_offset_description(self, hour_offset: int) -> str:
        """Retourne une description lisible du d√©calage horaire"""
        if hour_offset == 1:
            return "prochaine heure"
        elif hour_offset == 0:
            return "heure actuelle"
        elif hour_offset == -1:
            return "heure pr√©c√©dente"
        else:
            sign = '+' if hour_offset > 0 else ''
            return f"heure actuelle{sign}{hour_offset}"

    def _load_airports_data(self) -> Optional[pd.DataFrame]:
        """Charge les donn√©es des a√©roports depuis le fichier CSV"""
        csv_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 
            "utils", 
            "airports_ref.csv"
        )
        
        if not os.path.exists(csv_path):
            self.logger.error(f"Fichier {csv_path} non trouv√©")
            return None
        
        try:
            return pd.read_csv(csv_path, sep=';', encoding='utf-8')
        except Exception as e:
            self.logger.error(f"Impossible de lire le fichier CSV: {e}")
            return None

    def _fetch_airport_flights(self, iata_code: str, timezone_name: str, 
                             utc_now: datetime, hour_offset: int, 
                             index: int, total: int, ftp_config: Optional[Dict] = None) -> List[Dict]:
        """R√©cup√®re les vols pour un a√©roport sp√©cifique"""
        try:
            # Obtenir le timezone de l'a√©roport
            airport_tz = pytz.timezone(timezone_name)
            
            # Convertir l'heure UTC actuelle vers l'heure locale de l'a√©roport
            local_time = utc_now.astimezone(airport_tz)
            
            # Calculer l'heure cible avec le d√©calage sp√©cifi√©
            target_hour = local_time.replace(
                minute=0, second=0, microsecond=0
            ) + timedelta(hours=hour_offset)
            
            # Formater la date et l'heure pour la requ√™te
            date_str = target_hour.strftime("%Y-%m-%d")
            shift = target_hour.strftime("%H")
            
            self.logger.debug(f"{index + 1}/{total} - {iata_code} | "
                  f"Heure locale: {local_time.strftime('%H:%M')} | "
                  f"Heure cible: {shift}h | Date: {date_str} | "
                  f"Offset: {hour_offset:+d}h")
            
            # Faire la requ√™te pour cette heure sp√©cifique
            flights = self.fetch(
                iata_airport=iata_code,
                date=date_str,
                dep_arr="departure",
                shift=shift,
                ftp_config=ftp_config
            )
            
            # Ajouter des m√©tadonn√©es sur l'a√©roport
            if flights:
                for flight in flights:
                    flight['airport_timezone'] = timezone_name
                    flight['local_time'] = target_hour.strftime("%Y-%m-%d %H:%M:%S")
                    flight['utc_offset'] = str(target_hour.utcoffset())
            
            return flights
            
        except Exception as e:
            self.logger.error(f"Erreur pour l'a√©roport {iata_code}: {e}")
            return []


def main():
    """Fonction principale d'ex√©cution du scraper"""
    logger = get_logger(__name__)
    logger.info("Lancement du scraper...")
    scraper = FlightDataScraper()

    # Option pour r√©cup√©rer les d√©parts avec diff√©rents d√©calages horaires
    # Exemples d'utilisation :
    # next_hour_flights = scraper.fetch_next_hour_departures_top_airports(num_airports=10, delay=1.0, hour_offset=1)   # Prochaine heure (d√©faut)
    # current_hour_flights = scraper.fetch_next_hour_departures_top_airports(num_airports=10, delay=1.0, hour_offset=0)  # Heure actuelle
    # previous_hour_flights = scraper.fetch_next_hour_departures_top_airports(num_airports=10, delay=1.0, hour_offset=-1) # Heure pr√©c√©dente
    # future_flights = scraper.fetch_next_hour_departures_top_airports(num_airports=10, delay=1.0, hour_offset=3)       # Dans 3 heures

    next_hour_flights = scraper.fetch_next_hour_departures_top_airports(
        num_airports=5, 
        delay=1.5, 
        hour_offset=-24
    )
    logger.info(f"{len(next_hour_flights)} vols de d√©part r√©cup√©r√©s")


if __name__ == "__main__":
    main()



